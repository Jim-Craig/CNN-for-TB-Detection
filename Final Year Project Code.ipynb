{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/__init__.py:1473: The name tf.estimator.inputs is deprecated. Please use tf.compat.v1.estimator.inputs instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras \n",
    "import numpy as np \n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.python.client import device_lib\n",
    "# keras library import  for Saving and loading model and weights\n",
    "from keras.models import model_from_json\n",
    "from keras.models import load_model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Convolution2D, ZeroPadding2D, MaxPooling2D, Conv2DTranspose, Cropping2D\n",
    "from keras.layers import Input, Add, Dropout, Permute, add\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = os.listdir(\"Shenzen Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "original.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.ipynb_checkpoints'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clahe(bgr):\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "\n",
    "    lab_planes = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0,tileGridSize=(8,8))\n",
    "\n",
    "    lab_planes[0] = clahe.apply(lab_planes[0])\n",
    "\n",
    "    lab = cv2.merge(lab_planes)\n",
    "\n",
    "    bgr1 = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
    "    return bgr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(original), 262, 262, 3), dtype=np.float32)\n",
    "count = 0\n",
    "for file in original[1:]:\n",
    "    count = count + 1\n",
    "    n = original.index(file)\n",
    "    path1 = os.path.join('Shenzen Dataset/', file)\n",
    "    img = cv2.imread(path1, 1)\n",
    "    try:\n",
    "        img = cv2.resize(img, (262, 262))\n",
    "        img1 = clahe(img)\n",
    "        x[n] = img1/255\n",
    "    except Exception as  e:\n",
    "        print(e)\n",
    "        print(path1)\n",
    "        print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(660, 262, 262, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"shenzhen_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CHNCXR_0001_0.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>45</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CHNCXR_0002_0.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>63</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CHNCXR_0003_0.png</td>\n",
       "      <td>Female</td>\n",
       "      <td>48</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CHNCXR_0004_0.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>58</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CHNCXR_0005_0.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>28</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>657</th>\n",
       "      <td>CHNCXR_0658_1.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>41</td>\n",
       "      <td>bilateral secondary PTB  with right pneumothorax</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>658</th>\n",
       "      <td>CHNCXR_0659_1.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>33</td>\n",
       "      <td>secondary PTB  in the left upper field</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>659</th>\n",
       "      <td>CHNCXR_0660_1.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>1.bilateral secondary PTB  with right upper at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>CHNCXR_0661_1.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>26</td>\n",
       "      <td>bilateral secondary PTB  with right pleural th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>CHNCXR_0662_1.png</td>\n",
       "      <td>Male</td>\n",
       "      <td>32</td>\n",
       "      <td>secondary PTB  in the right upper field</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>662 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              study_id     sex  age  \\\n",
       "0    CHNCXR_0001_0.png    Male   45   \n",
       "1    CHNCXR_0002_0.png    Male   63   \n",
       "2    CHNCXR_0003_0.png  Female   48   \n",
       "3    CHNCXR_0004_0.png    Male   58   \n",
       "4    CHNCXR_0005_0.png    Male   28   \n",
       "..                 ...     ...  ...   \n",
       "657  CHNCXR_0658_1.png    Male   41   \n",
       "658  CHNCXR_0659_1.png    Male   33   \n",
       "659  CHNCXR_0660_1.png    Male   50   \n",
       "660  CHNCXR_0661_1.png    Male   26   \n",
       "661  CHNCXR_0662_1.png    Male   32   \n",
       "\n",
       "                                              findings  \n",
       "0                                               normal  \n",
       "1                                               normal  \n",
       "2                                               normal  \n",
       "3                                               normal  \n",
       "4                                               normal  \n",
       "..                                                 ...  \n",
       "657   bilateral secondary PTB  with right pneumothorax  \n",
       "658             secondary PTB  in the left upper field  \n",
       "659  1.bilateral secondary PTB  with right upper at...  \n",
       "660  bilateral secondary PTB  with right pleural th...  \n",
       "661            secondary PTB  in the right upper field  \n",
       "\n",
       "[662 rows x 4 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "normal                                                     326\n",
       "bilateral PTB                                               61\n",
       "Right PTB                                                   45\n",
       "PTB in the right upper field                                27\n",
       "left PTB                                                    19\n",
       "                                                          ... \n",
       "bilateral secondary PTB  with right pneumothorax             1\n",
       "secondary PTB  in the left lower field                       1\n",
       "Right PTB with fibrous changes                               1\n",
       "secondary PTB in the right upper field                       1\n",
       "Bilateral secondary PTB with left lower field pneumonia      1\n",
       "Name: findings, Length: 75, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.findings.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Better to turn every non\"Normal\" findings as TB. To make a Binary Classfier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = data[data[\"findings\"] != \"normal\"].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "data1.findings[a] = \"TB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TB        336\n",
       "normal    326\n",
       "Name: findings, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#So, we have a pretty balanced Dataset with the same amount of norma and TB values.\n",
    "data.findings.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              study_id   sex  age findings\n",
       " 118  CHNCXR_0119_0.png  Male   20   normal,\n",
       "               study_id   sex  age findings\n",
       " 376  CHNCXR_0377_1.png  Male   25       TB,\n",
       "               study_id   sex  age findings\n",
       " 537  CHNCXR_0538_1.png  Male   38       TB)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.study_id == \"CHNCXR_0119_0.png\"],data[data.study_id == \"CHNCXR_0377_1.png\"],data[data.study_id == \"CHNCXR_0538_1.png\"],"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "findings = data.findings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop([118, 376, 537],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>findings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [study_id, sex, age, findings]\n",
       "Index: []"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.study_id == \"CHNCXR_0538_1.png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.findings.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.reshape(Y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "Y = enc.fit_transform(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = x[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(659, 262, 262, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, x_test, Y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((461, 262, 262, 3), (198, 262, 262, 3))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((308, 262, 262, 3), (153, 262, 262, 3))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https:/github.com/qubvel/segmentation_models\n",
      "  Cloning https:///github.com/qubvel/segmentation_models to /tmp/pip-req-build-90ofhglx\n",
      "  Running command git clone -q https:///github.com/qubvel/segmentation_models /tmp/pip-req-build-90ofhglx\n",
      "  Running command git submodule update --init --recursive -q\n",
      "Requirement already satisfied: keras_applications<=1.0.8,>=1.0.7 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from segmentation-models==1.0.1) (1.0.8)\n",
      "Collecting image-classifiers==1.0.0\n",
      "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting efficientnet==1.0.0\n",
      "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: scikit-image in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from efficientnet==1.0.0->segmentation-models==1.0.1) (0.16.2)\n",
      "Requirement already satisfied: numpy>=1.9.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.18.5)\n",
      "Requirement already satisfied: h5py in /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages (from keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (2.10.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from h5py->keras_applications<=1.0.8,>=1.0.7->segmentation-models==1.0.1) (1.15.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.5.3)\n",
      "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (3.2.1)\n",
      "Requirement already satisfied: networkx>=2.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.5)\n",
      "Requirement already satisfied: pillow>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (8.1.0)\n",
      "Requirement already satisfied: imageio>=2.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.9.0)\n",
      "Requirement already satisfied: PyWavelets>=0.4.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.1.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (2.8.1)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from networkx>=2.0->scikit-image->efficientnet==1.0.0->segmentation-models==1.0.1) (4.4.2)\n",
      "Building wheels for collected packages: segmentation-models\n",
      "  Building wheel for segmentation-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segmentation-models: filename=segmentation_models-1.0.1-py3-none-any.whl size=33792 sha256=d6a8cc29a62cf76b9c16ba32c44ffd3cdf37c5681b46004ac344cab0a6230a0b\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-7c_boqko/wheels/0c/6e/ce/531a110b340b976440ab8d88c225ba2fdef043b8724973b97b\n",
      "Successfully built segmentation-models\n",
      "Installing collected packages: image-classifiers, efficientnet, segmentation-models\n",
      "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 segmentation-models-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https:///github.com/qubvel/segmentation_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow_p36/cpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras_applications/mobilenet_v2.py:294: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
      "  warnings.warn('`input_shape` is undefined or non-square, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/JonathanCMitchell/mobilenet_v2_keras/releases/download/v1.1/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9412608/9406464 [==============================] - 0s 0us/step\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.Sequential([  \n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu', input_shape=(262, 262,3),data_format=\"channels_last\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Conv2D(3, 3, activation='relu',data_format=\"channels_last\"),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(1, 1), padding='valid'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.applications.MobileNetV2(input_shape=(256, 256, 3), include_top=False, weights='imagenet'),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers. Flatten(),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "    tf.keras.layers.Dense(units=1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.35),\n",
    "    tf.keras.layers.Dense(units=2, activation='softmax'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 260, 260, 3)       84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 259, 259, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 259, 259, 3)       12        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 257, 257, 3)       84        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256, 256, 3)       12        \n",
      "_________________________________________________________________\n",
      "mobilenetv2_1.00_224 (Model) (None, 8, 8, 1280)        2257984   \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 8, 8, 1280)        5120      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 81920)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 81920)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1024)              83887104  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 86,152,450\n",
      "Trainable params: 86,115,766\n",
      "Non-trainable params: 36,684\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=tf.keras.optimizers.Adam(lr=1e-5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 461 samples, validate on 153 samples\n",
      "Epoch 1/5\n",
      "461/461 [==============================] - 104s 225ms/sample - loss: 0.0183 - acc: 0.9935 - val_loss: 0.0733 - val_acc: 0.9739\n",
      "Epoch 2/5\n",
      "461/461 [==============================] - 103s 224ms/sample - loss: 0.0207 - acc: 0.9957 - val_loss: 0.0668 - val_acc: 0.9739\n",
      "Epoch 3/5\n",
      "461/461 [==============================] - 104s 226ms/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.0538 - val_acc: 0.9804\n",
      "Epoch 4/5\n",
      "461/461 [==============================] - 102s 220ms/sample - loss: 0.0076 - acc: 0.9957 - val_loss: 0.0467 - val_acc: 0.9869\n",
      "Epoch 5/5\n",
      "461/461 [==============================] - 104s 225ms/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.0437 - val_acc: 0.9935\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(x = X_train, y = Y_train,\n",
    "        epochs=5,\n",
    "        batch_size = 10,\n",
    "        validation_data=(x_val, y_val),\n",
    "        shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x_test)\n",
    "y_pred = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       0., 1., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 1.,\n",
       "       1., 0., 0., 0., 1., 1., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n",
       "       0., 1., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 1.,\n",
       "       1., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 1., 1., 1., 1., 0., 1.,\n",
       "       1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
       "       1., 1., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "       1., 1., 0., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1., 0.,\n",
       "       0., 0., 0., 1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "       0., 1., 0., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "       0., 1., 0., 0., 1., 0., 0., 0., 1., 1., 0.])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test[:,1], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.84      0.84        94\n",
      "         1.0       0.86      0.86      0.86       104\n",
      "\n",
      "    accuracy                           0.85       198\n",
      "   macro avg       0.85      0.85      0.85       198\n",
      "weighted avg       0.85      0.85      0.85       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "print(sklearn.metrics.classification_report(y_test[:,1], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
